{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "# Load the MRI image\n",
    "image_path = '3_T2_MRI_SWI_BFC_50mm_HM_rsCMB_V1.nii.gz'  # Change this to the path of your MRI image\n",
    "mri_image = nib.load(image_path)\n",
    "mri_data = mri_image.get_fdata()\n",
    "\n",
    "# Iterate through each slice and save it as PNG\n",
    "for i in range(mri_data.shape[2]):  # Assuming the slice dimension is along the z-axis\n",
    "    slice_data = mri_data[:, :, i]  # Extract the slice data\n",
    "\n",
    "    # Plot and save the slice as PNG\n",
    "    plt.imshow(slice_data, cmap='gray')\n",
    "    plt.axis('off')  # Remove axis save \n",
    "    plt.savefig(f'slice_{i}.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Proccess where i should begin with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the data folder\n",
    "data_folder = 'data'\n",
    "\n",
    "# Load and preprocess the NIfTI files\n",
    "preprocessed_data = []\n",
    "\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith('.nii.gz'):\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        img = nib.load(filepath)\n",
    "        # Perform preprocessing steps here (e.g., resampling, normalization)\n",
    "        # Add the preprocessed image to the list\n",
    "        preprocessed_data.append(img.get_fdata())\n",
    "\n",
    "# Convert the preprocessed data to a numpy array\n",
    "preprocessed_data = np.array(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are not grayscale.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the data folder\n",
    "data_folder = 'data'\n",
    "\n",
    "# Load and preprocess the NIfTI files\n",
    "preprocessed_data = []\n",
    "\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith('.nii.gz'):\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        img = nib.load(filepath)\n",
    "        \n",
    "        # Extract the image data\n",
    "        img_data = img.get_fdata()\n",
    "        \n",
    "        # Convert the image to grayscale\n",
    "        if img_data.shape[-1] == 3:  # Check if the image has 3 channels\n",
    "            # Convert RGB to grayscale using the luminance method (weighted sum of RGB channels)\n",
    "            img_data_gray = np.dot(img_data[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "            \n",
    "            # Rescale pixel values to the range [0, 1]\n",
    "            img_data_gray /= img_data_gray.max()\n",
    "            \n",
    "            # Append the grayscale image to the preprocessed_data list\n",
    "            preprocessed_data.append(img_data_gray)\n",
    "        else:\n",
    "            # If the image is already grayscale, no conversion is needed\n",
    "            preprocessed_data.append(img_data)\n",
    "\n",
    "# Convert the preprocessed data to a numpy array\n",
    "preprocessed_data = np.array(preprocessed_data)\n",
    "\n",
    "# Check if the images are grayscale\n",
    "if preprocessed_data.shape[-1] == 1:\n",
    "    print(\"The images are grayscale.\")\n",
    "else:\n",
    "    print(\"The images are not grayscale.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (40, 176, 256, 80)\n",
      "Validation data shape: (5, 176, 256, 80)\n",
      "Testing data shape: (5, 176, 256, 80)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the preprocessed data into training, validation, and testing sets\n",
    "x_train, x_temp = train_test_split(preprocessed_data, test_size=0.2, random_state=42)\n",
    "x_val, x_test = train_test_split(x_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training data shape:\", x_train.shape)\n",
    "print(\"Validation data shape:\", x_val.shape)\n",
    "print(\"Testing data shape:\", x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# Define input shape\n",
    "input_shape = (176, 256, 80, 3)  # Assuming RGB images, change the number of channels accordingly\n",
    "# Define VAE model architecture\n",
    "latent_dim = 8\n",
    "# Encoder\n",
    "encoder_input = layers.Input(shape=input_shape)\n",
    "x = layers.Conv3D(32, kernel_size=3, activation='relu', padding='same')(encoder_input)\n",
    "x = layers.MaxPooling3D(pool_size=(2, 2, 2), padding='same')(x)\n",
    "x = layers.Conv3D(64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling3D(pool_size=(2, 2, 2), padding='same')(x)\n",
    "x = layers.Conv3D(128, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling3D(pool_size=(2, 2, 2), padding='same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "z_mean = layers.Dense(latent_dim)(x)\n",
    "z_log_var = layers.Dense(latent_dim)(x)\n",
    "\n",
    "# Reparameterization trick to sample from the latent space\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.random.normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Decoder\n",
    "decoder_input = layers.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(11 * 16 * 5 * 128, activation='relu')(decoder_input)\n",
    "x = layers.Reshape((11, 16, 5, 128))(x)\n",
    "x = layers.Conv3DTranspose(128, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling3D((2, 2, 2))(x)\n",
    "x = layers.Conv3DTranspose(64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling3D((2, 2, 2))(x)\n",
    "x = layers.Conv3DTranspose(32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling3D((2, 2, 2))(x)\n",
    "decoder_output = layers.Conv3DTranspose(3, kernel_size=3, activation='sigmoid', padding='same')(x)  # Adjust output channels\n",
    "\n",
    "# Define the VAE model\n",
    "encoder = Model(encoder_input, [z_mean, z_log_var, z], name='encoder')\n",
    "decoder = Model(decoder_input, decoder_output, name='decoder')\n",
    "vae_output = decoder(encoder(encoder_input)[2])\n",
    "vae = Model(encoder_input, vae_output, name='vae')\n",
    "\n",
    "# Define VAE loss\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = MeanSquaredError()(x, x_decoded_mean)\n",
    "    kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "# Compile the VAE model\n",
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "# Reshape the training, validation, and testing data\n",
    "# Make sure your data has the correct shape (176, 256, 80, 3)\n",
    "\n",
    "x_train = np.reshape(x_train, (-1, 176, 256, 80, 3))\n",
    "x_val = np.reshape(x_val, (-1, 176, 256, 80, 3))\n",
    "x_test = np.reshape(x_test, (-1, 176, 256, 80, 3))\n",
    "\n",
    "# Define number of epochs and batch size\n",
    "epochs = 20\n",
    "batch_size = 4\n",
    "# Train the VAE model\n",
    "history = vae.fit(x_train, x_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
